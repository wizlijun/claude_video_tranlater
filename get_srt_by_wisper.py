#!/opt/homebrew/bin/python3
"""
ç®€æ´çš„è§†é¢‘å­—å¹•æå–å’Œä¼˜åŒ–è„šæœ¬
ä½¿ç”¨æ–¹æ³•: python getsrt_simple.py video.mp4
è¾“å‡º: video.srt (ä¼˜åŒ–åçš„å­—å¹•æ–‡ä»¶)
"""

import os
import sys
import re
import json
import subprocess
import tempfile
import argparse
import time
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timedelta


class SimpleDisplay:
    """ç®€æ´è¿›åº¦æ˜¾ç¤ºå™¨"""
    
    def __init__(self):
        self.start_time = time.time()
    
    def step(self, step_num: int, total_steps: int, title: str):
        print(f"\nğŸ¬ æ­¥éª¤ {step_num}/{total_steps}: {title}")
    
    def info(self, message: str):
        print(f"  ğŸ“Œ {message}")
    
    def progress(self, message: str):
        print(f"  ğŸ”„ {message}")
    
    def success(self, message: str):
        print(f"  âœ… {message}")
    
    def error(self, message: str):
        print(f"  âŒ {message}")


class SubtitleOptimizer:
    """å­—å¹•ä¼˜åŒ–å™¨"""
    
    def __init__(self, display: SimpleDisplay):
        self.max_word_count_cjk = 25
        self.max_word_count_english = 18
        self.time_threshold_ms = 1000
        self.display = display
    
    def is_mainly_cjk(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸»è¦ç”±ä¸­æ—¥éŸ©æ–‡å­—ç»„æˆ"""
        cjk_patterns = [
            r'[\u4e00-\u9fff]',  # ä¸­æ—¥éŸ©ç»Ÿä¸€è¡¨æ„æ–‡å­—
            r'[\u3040-\u309f]',  # æ—¥æ–‡å¹³å‡å
            r'[\u30a0-\u30ff]',  # æ—¥æ–‡ç‰‡å‡å
            r'[\uac00-\ud7af]',  # éŸ©æ–‡éŸ³èŠ‚
        ]
        
        cjk_count = 0
        for pattern in cjk_patterns:
            cjk_count += len(re.findall(pattern, text))
        
        total_chars = len(re.sub(r'\s', '', text))
        return cjk_count / total_chars > 0.5 if total_chars > 0 else False
    
    def count_words(self, text: str) -> int:
        """ç»Ÿè®¡å¤šè¯­è¨€æ–‡æœ¬ä¸­çš„å­—ç¬¦/å•è¯æ•°"""
        if self.is_mainly_cjk(text):
            return len(re.sub(r'[\s\W]', '', text))
        else:
            return len(text.split())
    
    def srt_time_to_seconds(self, srt_time: str) -> float:
        """Convert SRT time format to seconds"""
        time_parts = srt_time.replace(',', '.').split(':')
        hours = int(time_parts[0])
        minutes = int(time_parts[1])
        seconds = float(time_parts[2])
        return hours * 3600 + minutes * 60 + seconds
    
    def seconds_to_srt_time(self, seconds: float) -> str:
        """Convert seconds to SRT time format"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        ms = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"
    
    def parse_srt(self, srt_content: str) -> List[Dict]:
        """è§£æSRTæ–‡ä»¶å†…å®¹"""
        blocks = re.split(r'\n\s*\n', srt_content.strip())
        segments = []
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                index = lines[0]
                time_line = lines[1]
                text = '\n'.join(lines[2:])
                
                match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', time_line)
                if match:
                    start_time = self.srt_time_to_seconds(match.group(1))
                    end_time = self.srt_time_to_seconds(match.group(2))
                    segments.append({
                        'index': int(index),
                        'start': start_time,
                        'end': end_time,
                        'text': text.strip()
                    })
        
        return segments
    
    def segments_to_srt(self, segments: List[Dict]) -> str:
        """å°†æ®µè½åˆ—è¡¨è½¬æ¢ä¸ºSRTæ ¼å¼"""
        srt_content = ""
        for i, seg in enumerate(segments, 1):
            srt_content += f"{i}\n"
            srt_content += f"{self.seconds_to_srt_time(seg['start'])} --> {self.seconds_to_srt_time(seg['end'])}\n"
            srt_content += f"{seg['text']}\n\n"
        return srt_content
    
    def optimize_subtitle(self, srt_content: str) -> str:
        """æ‰§è¡Œå®Œæ•´çš„å­—å¹•ä¼˜åŒ–æµç¨‹"""
        segments = self.parse_srt(srt_content)
        if not segments:
            return srt_content
        
        original_count = len(segments)
        
        # ä¼˜åŒ–æ—¶é—´æˆ³
        threshold_sec = self.time_threshold_ms / 1000.0
        for i in range(len(segments) - 1):
            current = segments[i]
            next_seg = segments[i + 1]
            time_gap = next_seg['start'] - current['end']
            if 0 < time_gap < threshold_sec:
                mid_time = (current['end'] + next_seg['start']) / 2
                current['end'] = mid_time
                next_seg['start'] = mid_time
        
        # åˆå¹¶çŸ­å¥
        merged_segments = []
        i = 0
        while i < len(segments):
            current = segments[i]
            current_words = self.count_words(current['text'])
            
            should_merge = False
            if i < len(segments) - 1:
                next_seg = segments[i + 1]
                next_words = self.count_words(next_seg['text'])
                total_words = current_words + next_words
                max_words = self.max_word_count_cjk if self.is_mainly_cjk(current['text']) else self.max_word_count_english
                if (current_words < 5 or next_words < 5) and total_words <= max_words:
                    should_merge = True
            
            if should_merge:
                merged_text = current['text']
                if self.is_mainly_cjk(current['text']):
                    merged_text += next_seg['text']
                else:
                    merged_text += ' ' + next_seg['text']
                
                merged_segments.append({
                    'index': len(merged_segments) + 1,
                    'start': current['start'],
                    'end': next_seg['end'],
                    'text': merged_text
                })
                i += 2
            else:
                merged_segments.append({
                    'index': len(merged_segments) + 1,
                    'start': current['start'],
                    'end': current['end'],
                    'text': current['text']
                })
                i += 1
        
        # è¿‡æ»¤å™ªéŸ³
        filtered_segments = []
        for seg in merged_segments:
            text = seg['text'].strip()
            if not (text.startswith('ã€') or text.startswith('[') or 
                   text.startswith('(') or text.startswith('ï¼ˆ') or
                   text.startswith('â™ª') or text.startswith('â™«') or
                   len(text.strip()) == 0):
                filtered_segments.append({
                    'index': len(filtered_segments) + 1,
                    'start': seg['start'],
                    'end': seg['end'],
                    'text': text
                })
        
        final_count = len(filtered_segments)
        self.display.success(f"ä¼˜åŒ–å®Œæˆ: {original_count} -> {final_count} æ®µ")
        
        return self.segments_to_srt(filtered_segments)


class WhisperProcessor:
    """Whisperå¤„ç†å™¨"""
    
    def __init__(self, display: SimpleDisplay):
        self.model = "small"
        self.temperature = 0
        self.initial_prompt = "Generate full sentence punctuation based on the language. è¡¥å…¨æ ‡ç‚¹ç¬¦å·"
        self.display = display
    
    def probe_video_info(self, video_path: str) -> Dict:
        """æ¢æµ‹è§†é¢‘æ–‡ä»¶ä¿¡æ¯"""
        try:
            cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json',
                   '-show_format', '-show_streams', video_path]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            return json.loads(result.stdout)
        except:
            return {}
    
    def extract_audio(self, video_path: str, audio_path: str) -> bool:
        """ä»è§†é¢‘æå–éŸ³é¢‘"""
        file_ext = Path(video_path).suffix.lower()
        
        # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
        video_info = self.probe_video_info(video_path)
        if 'format' in video_info:
            duration = float(video_info['format'].get('duration', 0))
            size = int(video_info['format'].get('size', 0))
            self.display.info(f"è§†é¢‘æ—¶é•¿: {timedelta(seconds=int(duration))}, å¤§å°: {size / (1024*1024):.1f} MB")
        
        try:
            cmd = ['ffmpeg', '-i', video_path]
            
            # å¤šè½¨é“ä¼˜åŒ–
            if file_ext in ['.mov', '.mts', '.m2ts', '.mkv']:
                cmd.extend(['-map', '0:a:0'])
            
            cmd.extend([
                '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1',
                audio_path, '-y', '-hide_banner', '-loglevel', 'error'
            ])
            
            self.display.progress("å¼€å§‹æå–éŸ³é¢‘...")
            start_time = time.time()
            
            subprocess.run(cmd, check=True)
            
            extract_time = time.time() - start_time
            audio_file = Path(audio_path)
            if audio_file.exists() and audio_file.stat().st_size > 0:
                size_mb = audio_file.stat().st_size / (1024 * 1024)
                self.display.success(f"éŸ³é¢‘æå–å®Œæˆ (ç”¨æ—¶: {extract_time:.1f}s, å¤§å°: {size_mb:.1f}MB)")
                return True
            else:
                self.display.error("éŸ³é¢‘æ–‡ä»¶ä¸ºç©º")
                return False
                
        except subprocess.CalledProcessError as e:
            self.display.error(f"éŸ³é¢‘æå–å¤±è´¥: {e}")
            return False
        except FileNotFoundError:
            self.display.error("æœªæ‰¾åˆ° ffmpeg")
            return False
    
    def detect_language(self, audio_path: str) -> Optional[str]:
        """å¿«é€Ÿæ£€æµ‹è¯­è¨€"""
        self.display.progress("æ£€æµ‹éŸ³é¢‘è¯­è¨€...")
        
        try:
            cmd = [
                'whisper', audio_path,
                '--model', self.model,
                '--output_format', 'txt',
                '--output_dir', '/tmp',
                '--clip_timestamps', '0,30',
                '--verbose', 'True'  # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            ]
            
            # è®© Whisper çš„è¾“å‡ºç›´æ¥æ˜¾ç¤ºåœ¨ç»ˆç«¯ï¼ŒåŒæ—¶æ•è·è¾“å‡ºç”¨äºè§£æ
            result = subprocess.run(cmd, text=True)
            
            # è¯»å–ç”Ÿæˆçš„æ–‡ä»¶æ¥è·å–è¯­è¨€ä¿¡æ¯
            try:
                with open('/tmp/audio.txt', 'r', encoding='utf-8') as f:
                    content = f.read()
                    if content.strip():  # å¦‚æœæœ‰å†…å®¹ï¼Œè¯´æ˜æ£€æµ‹æˆåŠŸ
                        # ä»æ–‡ä»¶åæ¨æ–­è¯­è¨€ï¼ˆWhisperä¼šç”Ÿæˆå¸¦è¯­è¨€åç¼€çš„æ–‡ä»¶ï¼‰
                        temp_files = list(Path('/tmp').glob('audio*.txt'))
                        for temp_file in temp_files:
                            if temp_file.name != 'audio.txt':
                                # æ–‡ä»¶åæ ¼å¼å¯èƒ½æ˜¯ audio.en.txt ç­‰
                                parts = temp_file.stem.split('.')
                                if len(parts) > 1:
                                    detected_lang = parts[-1]
                                    self.display.success(f"æ£€æµ‹åˆ°è¯­è¨€: {detected_lang}")
                                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                                    try:
                                        os.remove('/tmp/audio.txt')
                                        os.remove(str(temp_file))
                                    except:
                                        pass
                                    return detected_lang
                        
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯­è¨€åç¼€ï¼Œé»˜è®¤è¿”å›è‹±æ–‡
                        self.display.success("æ£€æµ‹åˆ°è¯­è¨€: en")
                        try:
                            os.remove('/tmp/audio.txt')
                        except:
                            pass
                        return 'en'
            except:
                pass
            
            return None
            
        except Exception as e:
            return None
    
    def transcribe_cjk(self, audio_path: str, language: str, output_dir: str) -> str:
        """ä½¿ç”¨ä¼˜åŒ–çš„ä¸­æ—¥éŸ©é…ç½®è½¬å½•"""
        self.display.progress(f"ä½¿ç”¨ä¼˜åŒ–çš„{language}é…ç½®è½¬å½•...")
        
        try:
            cmd = [
                'whisper', audio_path,
                '--model', self.model,
                '--language', language,
                '--output_format', 'srt',
                '--output_dir', output_dir,
                '--no_speech_threshold', '0.3',
                '--logprob_threshold', '-0.8',
                '--compression_ratio_threshold', '1.8',
                '--temperature', str(self.temperature),
                '--initial_prompt', self.initial_prompt
            ]
            
            # è®© Whisper çš„è¾“å‡ºç›´æ¥æ˜¾ç¤ºåœ¨ç»ˆç«¯
            subprocess.run(cmd, check=True)
            
            audio_name = Path(audio_path).stem
            srt_path = Path(output_dir) / f"{audio_name}.srt"
            
            if srt_path.exists():
                self.display.success("ä¸­æ—¥éŸ©ä¼˜åŒ–é…ç½®è½¬å½•å®Œæˆ")
                return str(srt_path)
            else:
                raise FileNotFoundError(f"SRTæ–‡ä»¶æœªç”Ÿæˆ: {srt_path}")
                
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Whisperè½¬å½•å¤±è´¥: {e}")
    
    def transcribe_standard(self, audio_path: str, language: Optional[str], output_dir: str) -> str:
        """ä½¿ç”¨æ ‡å‡†é…ç½®è½¬å½•"""
        self.display.progress("ä½¿ç”¨æ ‡å‡†é…ç½®è½¬å½•...")
        
        try:
            cmd = [
                'whisper', audio_path,
                '--model', self.model,
                '--output_format', 'json',
                '--output_dir', output_dir,
                '--word_timestamps', 'True',
                '--temperature', str(self.temperature),
                '--initial_prompt', self.initial_prompt
            ]
            
            if language:
                cmd.extend(['--language', language])
            
            # è®© Whisper çš„è¾“å‡ºç›´æ¥æ˜¾ç¤ºåœ¨ç»ˆç«¯
            subprocess.run(cmd, check=True)
            
            audio_name = Path(audio_path).stem
            json_path = Path(output_dir) / f"{audio_name}.json"
            
            if json_path.exists():
                self.display.success("æ ‡å‡†é…ç½®è½¬å½•å®Œæˆ")
                return str(json_path)
            else:
                raise FileNotFoundError(f"JSONæ–‡ä»¶æœªç”Ÿæˆ: {json_path}")
                
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Whisperè½¬å½•å¤±è´¥: {e}")
    
    def json_to_srt(self, json_path: str) -> str:
        """å°†Whisper JSONè¾“å‡ºè½¬æ¢ä¸ºæ•´å¥çº§SRT"""
        self.display.progress("è½¬æ¢ä¸ºæ•´å¥çº§SRTæ ¼å¼...")
        
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æå–æ‰€æœ‰è¯çº§æ—¶é—´æˆ³
        all_words = []
        for segment in data['segments']:
            if 'words' in segment:
                for word_info in segment['words']:
                    all_words.append({
                        'word': word_info['word'].strip(),
                        'start': word_info['start'],
                        'end': word_info['end']
                    })
        
        if not all_words:
            raise ValueError("æœªæ‰¾åˆ°è¯çº§æ—¶é—´æˆ³")
        
        # åˆå¹¶æ–‡æœ¬å¹¶æŒ‰å¥å­åˆ†å‰²
        full_text = ' '.join([word['word'] for word in all_words])
        sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ])', full_text)
        
        # åˆå¹¶å¥å­å’Œæ ‡ç‚¹
        merged_sentences = []
        i = 0
        while i < len(sentences):
            sentence = sentences[i].strip()
            if i + 1 < len(sentences) and sentences[i + 1] in '.!?ã€‚ï¼ï¼Ÿ':
                sentence += sentences[i + 1]
                i += 2
            else:
                i += 1
            if sentence:
                merged_sentences.append(sentence.strip())
        
        # æ˜ å°„å¥å­åˆ°è¯çº§æ—¶é—´æˆ³
        sentence_segments = []
        word_index = 0
        
        for sentence_idx, sentence in enumerate(merged_sentences):
            sentence_words = sentence.replace('.', '').replace('!', '').replace('?', '').replace('ã€‚', '').replace('ï¼', '').replace('ï¼Ÿ', '').split()
            
            sentence_start_time = None
            sentence_end_time = None
            matched_word_count = 0
            
            search_start = word_index
            for i in range(search_start, len(all_words)):
                word_text = all_words[i]['word'].replace('.', '').replace('!', '').replace('?', '').replace('ã€‚', '').replace('ï¼', '').replace('ï¼Ÿ', '').replace(',', '').replace('ï¼Œ', '').strip()
                
                if matched_word_count < len(sentence_words):
                    target_word = sentence_words[matched_word_count].replace(',', '').replace('ï¼Œ', '').strip()
                    
                    if word_text.lower() == target_word.lower():
                        if sentence_start_time is None:
                            sentence_start_time = all_words[i]['start']
                        sentence_end_time = all_words[i]['end']
                        matched_word_count += 1
                        word_index = i + 1
                        
                        if matched_word_count >= len(sentence_words):
                            break
            
            # å¤‡ç”¨æ–¹æ¡ˆ
            if sentence_start_time is None or sentence_end_time is None:
                if sentence_idx == 0:
                    sentence_start_time = all_words[0]['start'] if all_words else 0
                else:
                    sentence_start_time = sentence_segments[-1]['end'] if sentence_segments else 0
                
                if sentence_end_time is None:
                    avg_duration = 0.5
                    estimated_duration = len(sentence_words) * avg_duration
                    sentence_end_time = sentence_start_time + estimated_duration
            
            sentence_segments.append({
                'start': sentence_start_time,
                'end': sentence_end_time,
                'text': sentence
            })
        
        # ç”ŸæˆSRTå†…å®¹
        srt_content = ""
        for i, segment in enumerate(sentence_segments, 1):
            start_time = self._seconds_to_srt_time(segment['start'])
            end_time = self._seconds_to_srt_time(segment['end'])
            srt_content += f"{i}\n{start_time} --> {end_time}\n{segment['text']}\n\n"
        
        # ç»Ÿè®¡åŒ¹é…å‡†ç¡®ç‡
        total_matched = sum([len(seg['text'].split()) for seg in sentence_segments])
        if len(all_words) > 0:
            accuracy = 100 * total_matched / len(all_words)
            self.display.success(f"è¯åŒ¹é…å‡†ç¡®ç‡: {accuracy:.1f}%")
        
        self.display.success(f"ç”Ÿæˆäº† {len(sentence_segments)} ä¸ªå­—å¹•æ®µè½")
        return srt_content
    
    def _seconds_to_srt_time(self, seconds: float) -> str:
        """Convert seconds to SRT time format"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        ms = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"


def main():
    parser = argparse.ArgumentParser(description='ç®€æ´çš„è§†é¢‘å­—å¹•æå–å’Œä¼˜åŒ–è„šæœ¬')
    parser.add_argument('video_file', help='è¾“å…¥è§†é¢‘æ–‡ä»¶')
    parser.add_argument('-l', '--language', default='auto', help='æŒ‡å®šè¯­è¨€ä»£ç  (é»˜è®¤: auto)')
    parser.add_argument('-o', '--output', help='è¾“å‡ºSRTæ–‡ä»¶å (é»˜è®¤: è§†é¢‘æ–‡ä»¶å.srt)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    video_path = Path(args.video_file)
    if not video_path.exists():
        print(f"âŒ é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        sys.exit(1)
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = video_path.with_suffix('.srt')
    
    # æ£€æŸ¥ä¾èµ–
    dependencies_ok = True
    
    try:
        subprocess.run(['whisper', '--help'], capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° whisperï¼Œè¯·å…ˆå®‰è£…: pip install openai-whisper")
        dependencies_ok = False
    
    try:
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° ffmpeg")
        dependencies_ok = False
    
    if not dependencies_ok:
        sys.exit(1)
    
    # æ˜¾ç¤ºå¼€å§‹ä¿¡æ¯
    print(f"\nğŸš€ è§†é¢‘å­—å¹•æå–å™¨")
    print(f"  è¾“å…¥: {video_path.name}")
    print(f"  è¾“å‡º: {output_path.name}")
    print(f"  è¯­è¨€: {args.language}")
    
    # åˆ›å»ºå¤„ç†å™¨
    display = SimpleDisplay()
    whisper = WhisperProcessor(display)
    optimizer = SubtitleOptimizer(display)
    
    total_start_time = time.time()
    
    # ä½¿ç”¨ä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        audio_path = temp_path / "audio.wav"
        
        try:
            # æ­¥éª¤1: æå–éŸ³é¢‘
            display.step(1, 3, "éŸ³é¢‘æå–")
            if not whisper.extract_audio(str(video_path), str(audio_path)):
                sys.exit(1)
            
            # æ­¥éª¤2: è¯­éŸ³è¯†åˆ«
            display.step(2, 3, "è¯­éŸ³è¯†åˆ«")
            
            # è¯­è¨€æ£€æµ‹å’Œå¤„ç†
            detected_language = args.language
            if args.language == 'auto':
                detected_language = whisper.detect_language(str(audio_path))
            
            # æ ¹æ®è¯­è¨€é€‰æ‹©å¤„ç†æ–¹å¼
            if detected_language and detected_language in ['zh', 'ja', 'ko']:
                # ä¸­æ—¥éŸ©ä½¿ç”¨ä¼˜åŒ–é…ç½®
                srt_path = whisper.transcribe_cjk(str(audio_path), detected_language, str(temp_path))
                with open(srt_path, 'r', encoding='utf-8') as f:
                    srt_content = f.read()
            else:
                # å…¶ä»–è¯­è¨€ä½¿ç”¨æ ‡å‡†é…ç½®
                json_path = whisper.transcribe_standard(str(audio_path), detected_language, str(temp_path))
                srt_content = whisper.json_to_srt(json_path)
            
            # ç»Ÿè®¡åŸå§‹æ®µè½æ•°
            original_segments = len(re.split(r'\n\s*\n', srt_content.strip()))
            display.success(f"è¯­éŸ³è¯†åˆ«å®Œæˆï¼Œç”Ÿæˆ {original_segments} ä¸ªæ®µè½")
            
            # æ­¥éª¤3: å­—å¹•ä¼˜åŒ–
            display.step(3, 3, "å­—å¹•ä¼˜åŒ–")
            optimized_srt = optimizer.optimize_subtitle(srt_content)
            
            # ä¿å­˜æœ€ç»ˆç»“æœ
            display.progress(f"ä¿å­˜åˆ° {output_path.name}...")
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(optimized_srt)
            
            total_time = time.time() - total_start_time
            
            # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
            final_segments = len(re.split(r'\n\s*\n', optimized_srt.strip()))
            
            print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
            display.success(f"è¾“å‡º: {output_path.name}")
            display.success(f"ç”¨æ—¶: {total_time:.1f}ç§’")
            
            if output_path.exists():
                file_size = output_path.stat().st_size
                display.info(f"æ®µè½: {final_segments}, å¤§å°: {file_size}å­—èŠ‚")
            
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
            sys.exit(1)
        except Exception as e:
            display.error(f"å¤„ç†å¤±è´¥: {e}")
            sys.exit(1)


if __name__ == "__main__":
    main()